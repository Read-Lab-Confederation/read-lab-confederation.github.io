<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>EMERGENT | OK Google, How do I Learn Data Science?</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=generator content="Hugo 0.79.1"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link href=/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css rel=stylesheet><link rel=stylesheet href=/css/custom.css><meta property="og:title" content="OK Google, How do I Learn Data Science?"><meta property="og:description" content="An R how-to guide to finding your how-to guides in Google Search history"><meta property="og:type" content="article"><meta property="og:url" content="https://read-lab-confederation.github.io/blog/posts/bt-google_grad/"><meta property="article:published_time" content="2021-08-16T00:00:00+00:00"><meta property="article:modified_time" content="2021-08-16T00:00:00+00:00"><meta itemprop=name content="OK Google, How do I Learn Data Science?"><meta itemprop=description content="An R how-to guide to finding your how-to guides in Google Search history"><meta itemprop=datePublished content="2021-08-16T00:00:00+00:00"><meta itemprop=dateModified content="2021-08-16T00:00:00+00:00"><meta itemprop=wordCount content="1920"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="OK Google, How do I Learn Data Science?"><meta name=twitter:description content="An R how-to guide to finding your how-to guides in Google Search history"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-148959477-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link href=/css/share-button.css rel=stylesheet></head><body class="ma0 avenir bg-near-white"><header class="cover bg-top" style=background-image:url(https://read-lab-confederation.github.io/images/bt-Image_5.jpg)><div class="pb3-m pb6-l bg-black-60"><nav class="pv3 ph3 ph4-ns tc tl-l" role=navigation><div class="flex-l justify-between items-center center"><a href=https://read-lab-confederation.github.io class="f3 fw2 hover-white no-underline white-90 dib">EMERGENT</a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f7 f4-ns fw4 dib pr1 pr3-ns"><a class="hover-white no-underline white-90" href=/about/ title="About page">About</a></li><li class="list f7 f4-ns fw4 dib pr1 pr3-ns"><a class="hover-white no-underline white-90" href=/blog/ title="Blog page">Blog</a></li><li class="list f7 f4-ns fw4 dib pr1 pr3-ns"><a class="hover-white no-underline white-90" href=/group/ title="Group page">Group</a></li><li class="list f7 f4-ns fw4 dib pr1 pr3-ns"><a class="hover-white no-underline white-90" href=/research/ title="Research page">Research</a></li><li class="list f5 f4-ns fw4 dib pr1 pr3-ns"><a href=https://twitter.com/tdread_emory target=_blank class="link-transition twitter link dib z-999 pt0-l mr1" title="Twitter link" rel=noopener aria-label="follow on Twitter——Opens in a new window"><svg height="24" style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" width="24" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" width="8" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg></span></a></li></ul></div></div></nav><div class="tc-l pv6-l pv4 ph3 ph4-ns"><h1 class="dib-ns dn f1-ns fw2 white-90 mb0 lh-title">OK Google, How do I Learn Data Science?</h1><h2 class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">An R how-to guide to finding your how-to guides in Google Search history</h2></div></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><p class="f6 b helvetica tracked">POSTS</p><h1 class="f3-ns f4 athelas mb1">OK Google, How do I Learn Data Science?</h1><time class="f6 dib tracked" datetime=2021-08-16T00:00:00Z>August 16, 2021</time><div class=author-info><p class=author-name>Brooke Talbot</p></div></header><section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-80-l"><p>Something that delights me as a data scientist is that concepts and techniques are very readily shared within the community. It&rsquo;s also astounding to me that each and every day we have access to an infinite body of knowledge which can help supplement formal and informal learning - namely, that we can gain a lot of information very quickly by turning to Professor Google! Investigating how we as scientists search this seemingly endless collection of facts and figures and code blocks, and for what exact purposes, can give some great insights into how we communicate and learn and ultimately improve our reseach.</p><h2 id=looking-at-my-google-search-history-over-time>Looking at my Google Search history over time</h2><p>I decided to take on this task of exploring just exactly how I learned from the internet in the past few years. With some significant help and inspiration <a href=https://towardsdatascience.com/explore-your-activity-on-google-with-r-how-to-analyze-and-visualize-your-search-history-1fb74e5fb2b6>from this delightful how-to guide</a> by Saúl Buentello, I extracted the Google Search history from my personal Google account and brought that data into RStudio.</p><p>Using Buentello&rsquo;s excellent web scraping code and then taking a couple of trips around the <a href=https://www.tidyverse.org/>Tidyverse</a> - voila! - I was able to filter down and count just how often I have used Google Search since I created the account back in 2009.</p><pre><code># LIBRARIES
library(lubridate)
library(rvest)
library(tidyverse)
library(magrittr)
library(data.table)


# CREATING SUBSET OF SCRAPED SEARCHED DATA FROM HISTORY
Searched &lt;- searchedData[(searchedData$type == &quot;Searched&quot;),]


# OVERALL PLOT
allSearched &lt;- ggplot(Searched, aes(x = year)) + 
               geom_bar(fill = &quot;gray48&quot;) + 
               theme_classic() +
               labs(x= &quot;Year&quot;, y= &quot;Count&quot;) + 
               ggtitle(&quot;How much do I use Google Search over time?&quot;)
allSearched
</code></pre><p><img src=/images/bt-Image_1.jpg alt></p><p>Unsurprisingly, I had a huge spike in the number of searches in the year 2020, which is likely the result of a mix of the switch to a work-from-home environment (&ldquo;how to update Zoom desktop&rdquo;), new-demands at work (&ldquo;how to get healthcare workers masks&rdquo;), and taking a big step in starting my current PhD program at Emory, switching fields from epidemiology to a course of study more focused on microbial genetics (&ldquo;what is Bioconda?").</p><h2 id=strategies-for-paring-down-to-learning-related-searches>Strategies for paring down to learning-related searches</h2><p>Of all these searches, though, I wondered what were the ones dedicated to teaching myself. I have been a student and/or early career scientist for the past 11 years and I know I have had a lot of questions. Personally, Google is my home search bar on my mobile device and my laptop, so many of my searches are lazy passageways to websites I want to access or funny pictures and videos I want to share, and it&rsquo;s also a decision making tool for finding whatever is a &ldquo;[insert resource here] near me.&rdquo;</p><p>I do have one idiosyncrasy which may be a hold-over from learning to use Ask Jeeves during elementary school computer science: I do, in fact, use question words for some of my searches. Although not a perfect dividing line, I figured this could be an excellent proxy for filtering down to searches that were instances where I was trying to learn something new. I used regular expressions to find common English question words (who, what, where, how, why, when) as well as the word &ldquo;tutorial&rdquo; and created a new variable which categorized my searches into questions and non-questions:</p><pre><code>#ADDED PADDING TO FRONT AND BACK OF STRING
Searched$search &lt;- paste(&quot; &quot;,Searched$search, &quot; &quot;, sep = &quot;&quot;)

#ASSIGNING QUESTION CATEGORY

Searched &lt;- Searched %&gt;% mutate(Questions = case_when(str_detect(search, &quot;how to|How to| How | how | why|Why| who | Who | when|When|what|What|where|Where|tutorial&quot;) == &quot;TRUE&quot; ~ 1, TRUE ~ 0)) %&gt;% mutate(Questions = as.factor(Questions))

Searched_Q_Sum &lt;- Searched %&gt;% group_by(year, month, day, Questions) %&gt;% summarise(n = n()) 

questionsSearched &lt;- ggplot(Searched_Q_Sum, aes(x = year, y=n, fill=Questions)) + 
                     geom_bar(position=&quot;stack&quot;, stat=&quot;identity&quot;) +
                     theme_classic() +
                     scale_fill_discrete(type = c(&quot;gray48&quot;,&quot;darkolivegreen2&quot;),name = &quot;Question Search&quot;, labels = c(&quot;No&quot;, &quot;Yes&quot;)) +
                     labs(x= &quot;Year&quot;, y= &quot;Count&quot;) + 
                     ggtitle(&quot;How often do I ask Professor Google a question?&quot;)
questionsSearched
</code></pre><p><img src=/images/bt-Image_2.jpg alt></p><p>These phrases make up about 6.6% of all of my searches (2,528 of 38,269 searches!), which while proportionally small is still a tractable amount to work with. So far so good. But what about the kinds of things I am trying to learn with these questions?</p><h2 id=subsetting-the-computational-questions>Subsetting the computational questions</h2><p>I shifted fields when I started my PhD program, and with that shift also came a shift in computational languages. I had a sense that many of my more recent searches would probably be related to understanding R, Python, and Bash script, and I was curious what impact this sudden shift in learning would have on my search history. As I mentioned, the positions I have held during this time involved a lot of training, some of which also included learning other languages and softwares, so how much did my first year of self-driven PhD research alter my patterns?</p><p>Similar to my &ldquo;Questions&rdquo; variable, I used regular expressions to find the searches with key phrases that I knew were most likely related to computation and research/work. This included names of programming languages, analytical softwares, hardware terms, common functions, file types and statistical concepts. I also sorted the searches with phrases that are related to analysis and bioinformatics while excluding phrases that were more likely to relate to general concepts in my field. For example the search &ldquo;what is a consensus tree&rdquo; is a computational search because I was almost certainly applying this directly to a phylogenetic tree analysis, but the search &ldquo;what is the comparative method [in] evolutionary biology&rdquo; is not computational because it relates to background knowledge I was gaining about a specific biological concept. I also excluded software or program names that were related to more social or leisure activities from the computation category, such as Instagram and Facebook. So, what does that look like?</p><pre><code>#SETTING UP COMPUTATIONAL VARIABLE

Searched &lt;- Searched %&gt;% mutate(Computational = case_when(str_detect(search, &quot; r |axis|data|graph|Graph|label|plot|phylogenetic|vim|code| in r |unix|grep|linux|unix|commandline|ggtree|ggplot|vector|bash|invariant sites|fastq|fasta|sas|SAS|shell script|matrix| R|rmarkdown|alignment|gunzip|gzip|untar|conda|sql|iqtree|gz file|shortbred|github|command| row|python|software|calculate|incidence|odds ratio|tableau|endnote|snippy-core|.sh|qsub|compare|citations|consensus|consensus tree| png |robinson-| fna |n50|google search|browsing|fastly| median |heatmap|brewer.pal|sequence file|newscale fill|vcf|CFML|unite function| cp |SNP|dirpath| awk | vi |.exe|binary file|bam file|bootstrap value|ubuntu|control c|metagenomic|paired end reads|bowtie1|bowtie2| excel |Use_Dev|snippy|YAML|travis| gbk |unit test|variant calling|biobakery|statistical power|treeio|json|xmfa| tar |disty|parsnp|gingr|harvest tools|jupyter| wsl |confidence intervals|power calculations|maximum likelihood| proc |mantel haenszel|knit to powerpoint|xml|tidyverse| irr |powerpoint|t-test|download|iqr|attack rate|nodupkey|pdf|stdev.s|set statements|access=read| e value|MAVEN|maven|DCPHIS|propensity score|$500.|best32|positive predictive value|attributable risk|effect measure modification| translate a page|prevalence ratio| bic number|negative predictive|NPV|image j|imageJ|P drive|I drive|heading error|\r|parallel|bioinformatics|genbank&quot;) == &quot;TRUE&quot; &amp; Questions == 1 ~ 1, TRUE ~ 0)) %&gt;% mutate(Computational = as.factor(Computational))

Searched_C_Sum &lt;- Searched %&gt;% group_by(year, month, day, Questions, Computational) %&gt;% summarise(n = n()) 


computationalQs &lt;- ggplot(Searched_C_Sum[which(Searched_C_Sum$Questions==&quot;1&quot;),], aes(x = year, y=n, fill=Computational)) + 
                     geom_bar(position=&quot;stack&quot;, stat=&quot;identity&quot;) +
                     theme_classic() +
                     scale_fill_discrete(type = c(&quot;gray48&quot;,&quot;darkolivegreen2&quot;), name = &quot;Computational Question&quot;, labels = c(&quot;No&quot;, &quot;Yes&quot;)) +
                     labs(x= &quot;Year&quot;, y= &quot;Count&quot;) + 
                     ggtitle(&quot;How often am I asking for computational help from Professor Google?&quot;)
computationalQs
</code></pre><p><img src=/images/bt-Image_3.jpg alt></p><p>It&rsquo;s quite shocking to me that proportionally the year 2020 really took a hold of my computational questions. After all, I really started to learn how to work with robust statistical programs in 2016, and a lot of my job as an epidemiologist revolved around trying (and failing and trying again) to build and analyze large datasets. One reason for the shift could be that I really did take on learning much more computation in the last year. Other reasons, too, could be related to a bias in my search behavior changing in 2020, including using the question format more frequently (Sorry Jeeves!), or switching from a work device which is sometimes logged into my account versus a personal device which is almost always logged into my account.</p><p>In any case, there are any number of other ways to query these data, and Buentello&rsquo;s guide has some lovely examples for breaking up searches by week, month, and time of day. For fun, I thought I would look at my total question searches by day of the week:</p><pre><code>#COMPUTATIONAL QUESTIONS BY DAY

ComputationalQsDay &lt;- ggplot(Searched_C_Sum[which(Searched_C_Sum$Questions==&quot;1&quot;),], aes(x = day, y=n, fill=Computational)) + 
                     geom_bar(position=&quot;stack&quot;, stat=&quot;identity&quot;) +
                     theme_classic() +
                     scale_fill_discrete(type = c(&quot;gray48&quot;,&quot;darkolivegreen2&quot;), name = &quot;Computational Question&quot;, labels = c(&quot;No&quot;, &quot;Yes&quot;)) +
                     labs(x= &quot;Weekday&quot;, y= &quot;Count&quot;) + 
                     ggtitle(&quot;How often do I ask for computational help by weekday?&quot;)
ComputationalQsDay
</code></pre><p><img src=/images/bt-Image_4.jpg alt></p><p>I guess I am quite inspired or wired on Wednesdays!</p><p>And if I zoom in on 2020 to look at the change-over to becoming a student, starting in the Fall:</p><pre><code># AND BREAKING OUT BY MONTH IN 2020

Day_years  &lt;- ggplot(Searched_C_Sum[which(Searched_C_Sum$Questions==&quot;1&quot; &amp; Searched_C_Sum$year %in% c(&quot;2020&quot;)),], aes(x = day, y=n, fill=Computational)) + geom_bar(position=&quot;stack&quot;, stat=&quot;identity&quot;) + 
  facet_wrap(vars(month)) + 
  theme_classic() +
  theme(strip.background = element_blank(), 
        axis.text = element_text(size = 10), 
        strip.text.x = element_text(size = 12, face = &quot;bold&quot;), 
        title = element_text(size = 16)) +                                                   
  scale_x_discrete(labels = c(&quot;Sun&quot;, &quot;Mon&quot;, &quot;Tues&quot;, &quot;Wed&quot;, &quot;Thurs&quot;, &quot;Fri&quot;, &quot;Sat&quot;)) +
  scale_fill_discrete(type = c(&quot;gray48&quot;,&quot;darkolivegreen2&quot;), name = &quot;Computational Question&quot;, labels = c(&quot;No&quot;, &quot;Yes&quot;)) +
  labs(x= &quot;Weekday&quot;, y= &quot;Count&quot;, title = &quot;What days did I ask a computational quesiton in 2020?&quot; ) 

# SILLY LABEL TEXT
ann_text &lt;- data.frame(day = &quot;Wednesday&quot;, n = 29 ,lab = &quot;Text&quot;,
                      month = factor(&quot;Sep&quot;, levels = c(&quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;, &quot;Oct&quot;, &quot;Nov&quot;, &quot;Dec&quot;)), Computational = factor(&quot;0&quot;, levels = c(&quot;0&quot;,&quot;1&quot;)))

Day_years + geom_label(data = ann_text,label = &quot;Seriously, what is Bioconda?&quot;, size = 4, show.legend = FALSE, fill = &quot;white&quot; )

</code></pre><p><img src=/images/bt-Image_5.jpg alt></p><p>I guess the Wednesday trend and the volume increase really does line up with the start of the semester!</p><h2 id=google-search-history-is-pretty-much-brain-vomit>Google search history is pretty much brain vomit</h2><p>A couple of issues came up in sorting my final data. For one, trying to sort out question words was imperfect when faced with commonly searched acronyms in my field. As someone involved in Public Health research, the World Health Organization (&ldquo;WHO&rdquo;) came up a fair number of times. Similarly, trying to use a word like &ldquo;guide&rdquo; resulted in a similar mix of my own education and work-related references, and the very revealing fact that The Hitchhiker&rsquo;s Guide to the Galaxy is my favorite book. Secondly, &ldquo;computational&rdquo; definitely became a hunt-and-peck adventure when using regular expressions. I also recognize that I have other more chaotic ways of searching for help with my code, and ultimately that means those searches were excluded from this particular analysis, resulting in a major under-representation of my dependency.</p><h2 id=whats-next>What&rsquo;s Next?</h2><p>Nevertheless, I think this was an excellent introspective project, and got me thinking about how to search and sift through research data by picking up on patterns that can act as flags for a final analysis. Your search history is a rich source of data, so it makes for fun practice both for the techniques and for developing interesting questions. For the future, I think it would be interesting to see if there is a pattern in the sites I actually visit as a result of these searches, as these are likely to have a bit more repetition and standardization in the free text. Perhaps as I improve my skills during my studies I will come up with even better ways to tackle this question of &ldquo;How do I use the internet to learn?&rdquo; and I look forward to seeing how the trends change in four- or five-years time.</p><h2 id=tldr>TL;DR</h2><ul><li>Google Search history can be readily brought into R, scraped, and used to detect patterns in learning or self-teaching, especially when it comes to computational learning.</li><li>I detected a really interesting increase in how I use Google, particularly regarding how to learn how to conduct computational techniques for my research, as soon as I became a PhD student.</li><li>Working with my Google Search history was excellent and fun practice in regular expressions and graphical display.</li><li>You can find <a href=https://github.com/bmtalbot/Google-Search-History/blob/main/README.md>the full code here</a> to create these graphs and play around with the computational and question variables, and I highly recommend <a href=https://towardsdatascience.com/explore-your-activity-on-google-with-r-how-to-analyze-and-visualize-your-search-history-1fb74e5fb2b6>this how-to guide</a> for scraping your Google Search history.</li></ul><ul class=pa0></ul><div class=mt6></div></section><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://read-lab-confederation.github.io>&copy; 2022 EMERGENT</a><div><a class=resp-sharing-button__link href="https://twitter.com/intent/tweet/?text=Check out EMERGENT, a bacterial genomics and metagenomics blog from @tdread_emory's group!&url=https://read-lab-confederation.github.io" target=_blank rel=noopener aria-label="Share on Twitter"><div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--large"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M23.44 4.83c-.8.37-1.5.38-2.22.02.93-.56.98-.96 1.32-2.02-.88.52-1.86.9-2.9 1.1-.82-.88-2-1.43-3.3-1.43-2.5.0-4.55 2.04-4.55 4.54.0.36.03.7.1 1.04-3.77-.2-7.12-2-9.36-4.75-.4.67-.6 1.45-.6 2.3.0 1.56.8 2.95 2 3.77-.74-.03-1.44-.23-2.05-.57v.06c0 2.2 1.56 4.03 3.64 4.44-.67.2-1.37.2-2.06.08.58 1.8 2.26 3.12 4.25 3.16C5.78 18.1 3.37 18.74 1 18.46c2 1.3 4.4 2.04 6.97 2.04 8.35.0 12.92-6.92 12.92-12.93.0-.2.0-.4-.02-.6.9-.63 1.96-1.22 2.56-2.14z"/></svg></div>Share on Twitter</div></a></div></div></footer><script src=/dist/js/app.3fc0f988d21662902933.js></script><script src=/js/custom.js></script></body></html>